{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgement\n",
    "\n",
    "Code in this notebook is based on the blog posts by the author of `tsfresh`, Nils Braun:\n",
    "\n",
    "- tsfresh on Large Data Samples [Part 1](https://towardsdatascience.com/time-series-feature-extraction-on-really-large-data-samples-b732f805ba0e) & [Part 2](https://towardsdatascience.com/tsfresh-on-large-data-samples-part-ii-4d6843155dfc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does `tsfresh` handle large data?\n",
    "\n",
    "If the size of the data is very large (large number of time series; each time series consisting of large number of samples), we face two types of challenges: \n",
    "\n",
    "- Larger execution time while computing the features (Compute bound problem)\n",
    "- Need for larger RAM (Memory bound problem)\n",
    "\n",
    "`tsfresh` addresses both in the following way. \n",
    "\n",
    "### Large Execution Time\n",
    "**If data fits into main memory(RAM)**, `tsfresh` solves the large execution time problem, by utlizing\n",
    "- **multiple processors in a single machine** (using `multiprocessing` package). This is the default option. Whenever, `tsfresh` package is used, multiprocessing is switched on by default. Number of processors/cores to be used can be cotrolled using `n_jobs` flag.\n",
    "- **multiple processors spread across multiple machines** (Cluster/Distributed Computing). `tsfresh.utilities.distribution` module consists of distributors including Dask based `tsfresh.utilities.distribution.ClusterDaskDistributor`. `ClusterDaskDistributor` distributes the job across various workers in a Dask cluster.\n",
    "\n",
    "### Need for larger memory\n",
    "**If data doesn't fit into main memory(RAM)**, `tsfresh` utilizes `Dask` for **out of core computation** and for **distributing** data across multiple machines in a cluster. `tsfresh` provides convenience function for this: `tsfresh.convenience.bindings.dask_feature_extraction_on_chunk`.\n",
    "\n",
    "`tsfresh` provides convenience function which addresses large data issue using **Apache Spark** as well (`tsfresh.convenience.bindings.spark_feature_extraction_on_chunk()`). However, this notebook focuses only on Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def get_segment_id_from_path(df, path):\n",
    "    \"\"\"\n",
    "    Returns the segment_id from the path of the file \n",
    "    \"\"\"\n",
    "    df.segment_id = df.segment_id.str.replace(path, \"\", regex=False)\n",
    "    df.segment_id = df.segment_id.str.replace(\".csv\", \"\", regex=False)\n",
    "    df.segment_id = df.segment_id.astype(np.int64)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def append_time_column(df):\n",
    "    df[\"time\"] = range(0, len(df))\n",
    "    \n",
    "    return df\n",
    "\n",
    "DATA_DIR = \"/datadrive/arnab/vssexclude/kaggle/volcano/data/train\"\n",
    "\n",
    "# Define the datatypes for different sensor data\n",
    "data_types = {\"sensor_1\" : np.float32, \n",
    "                 \"sensor_2\" : np.float32, \n",
    "                 \"sensor_3\" : np.float32,\n",
    "                 \"sensor_4\" : np.float32,\n",
    "                 \"sensor_5\" : np.float32,\n",
    "                 \"sensor_6\" : np.float32,\n",
    "                 \"sensor_7\" : np.float32,\n",
    "                 \"sensor_8\" : np.float32,\n",
    "                 \"sensor_9\" : np.float32,\n",
    "                 \"sensor_10\" : np.float32}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data fits into memory, but needs distribute FE job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use?\n",
    "\n",
    "- When data fits into memory, but we need to distribute the feature engineering job across a distributed Cluster to introduce more parallelism.\n",
    "\n",
    "### Steps\n",
    "- Start a Dask Cluster\n",
    "- Create an instance of `ClusterDaskDistributor` and connect to the Dask Scheduler created in above\n",
    "- Read Data (Pandas DataFrame)\n",
    "- Pass the `ClusterDaskDistributor` instance created above to the `extract_features` function of `tsfresh`\n",
    "- Extract features. Extracted features would also be Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start Dask Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/dask_architechture_diagram.png\" width=\"600\" height=\"200\" style=\"border-style: solid;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a LocalCluster with client, scheduler and worker running on the same machine. The scheduler will run on port 8786.\n",
    "\n",
    "By specifying `n_worker=8`, we have asked to dask to start `8` independent python processes. Based on the nature of the cluster, they may run in the same machine or different machines. In our case, the processes have been started in this machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tcp://127.0.0.1:8786'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCluster(n_workers=8, \n",
    "                       threads_per_worker=1, \n",
    "                       scheduler_port=8786, \n",
    "                       memory_limit='2GB')\n",
    "\n",
    "cluster.scheduler_address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Connect the `ClusterDaskDistributor` to the Dask Cluster created above. \n",
    "\n",
    "`ClusterDaskDistributor` is nothing but a `dask.distributed.Client`. I am using a local Dask cluster here, but, ideally it should be remote cluster. In fact, `tsfresh` provides an interface called `LocalDaskDistributor` for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>16.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:8786' processes=8 threads=8, memory=16.00 GB>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tsfresh.utilities.distribution import ClusterDaskDistributor\n",
    "\n",
    "# Connect to Dask Scheduler\n",
    "dask_distributor = ClusterDaskDistributor(address=\"127.0.0.1:8786\")\n",
    "\n",
    "dask_distributor.client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read Data\n",
    "\n",
    "Both input data and output data (extracted features) is Pandas DataFrame, Hence, entire data must fit into the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data for segment: 1400253000\n",
      "Reading data for segment: 140031872\n",
      "Reading data for segment: 1400727315\n",
      "Reading data for segment: 1400929225\n",
      "Reading data for segment: 1402556914\n",
      "Reading data for segment: 1402674973\n",
      "Reading data for segment: 1402914692\n",
      "Reading data for segment: 1403005697\n",
      "Reading data for segment: 1403222059\n",
      "Reading data for segment: 1403244730\n",
      "Reading data for segment: 1403440092\n",
      "Reading data for segment: 140348256\n",
      "Reading data for segment: 1403947680\n",
      "Reading data for segment: 1404122310\n",
      "Reading data for segment: 1404179874\n",
      "Reading data for segment: 1404322654\n",
      "Reading data for segment: 1404502479\n",
      "Reading data for segment: 1405189645\n",
      "Reading data for segment: 1405443107\n",
      "Reading data for segment: 1406234149\n",
      "Reading data for segment: 1406456924\n",
      "Reading data for segment: 1406626451\n",
      "Reading data for segment: 1406938061\n",
      "Reading data for segment: 1407084157\n",
      "Reading data for segment: 1407094442\n",
      "Reading data for segment: 1407261706\n",
      "Reading data for segment: 1408285202\n",
      "Reading data for segment: 140851065\n",
      "Reading data for segment: 1408645616\n",
      "Reading data for segment: 1408663387\n",
      "Reading data for segment: 1409167039\n",
      "\n",
      "\n",
      "Shape of the dataframe consisting of all data from above files: (31000, 4)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for name in glob.glob(f\"{DATA_DIR}/140*\"):\n",
    "    temp_df = pd.read_csv(name, \n",
    "                          dtype=data_types, \n",
    "                          usecols=[\"sensor_1\", \"sensor_4\"], \n",
    "                          nrows=1000)\n",
    "    \n",
    "    # Extract name of the segment from the file name\n",
    "    segment_id = int(name.split(\".\")[0].split(\"/\")[-1])\n",
    "    temp_df[\"segment_id\"] = segment_id\n",
    "    print(f\"Reading data for segment: {segment_id}\")\n",
    "    \n",
    "    # Create a column named time\n",
    "    temp_df[\"time\"] = range(0, len(temp_df))\n",
    "    \n",
    "    df = df.append(temp_df)\n",
    "    \n",
    "print(\"\\n\")    \n",
    "print(f\"Shape of the dataframe consisting of all data from above files: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-486.0</td>\n",
       "      <td>-516.0</td>\n",
       "      <td>1400253000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-567.0</td>\n",
       "      <td>-591.0</td>\n",
       "      <td>1400253000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-631.0</td>\n",
       "      <td>-620.0</td>\n",
       "      <td>1400253000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-744.0</td>\n",
       "      <td>-550.0</td>\n",
       "      <td>1400253000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-725.0</td>\n",
       "      <td>-475.0</td>\n",
       "      <td>1400253000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_1  sensor_4  segment_id  time\n",
       "0    -486.0    -516.0  1400253000     0\n",
       "1    -567.0    -591.0  1400253000     1\n",
       "2    -631.0    -620.0  1400253000     2\n",
       "3    -744.0    -550.0  1400253000     3\n",
       "4    -725.0    -475.0  1400253000     4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4, 5, 6. Extract fetuares using `tsfresh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass the `ClusterDaskDistributor` instance created above to the `extract_features` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh.feature_extraction import extract_features\n",
    "from tsfresh.feature_extraction.settings import ComprehensiveFCParameters\n",
    "\n",
    "extracted_features = extract_features(timeseries_container=df,\n",
    "                     column_id='segment_id', column_sort='time',\n",
    "                     default_fc_parameters=ComprehensiveFCParameters(),\n",
    "                     distributor=dask_distributor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Close the Dask Client and Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_distributor.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, dask_distributor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data doesn't fit intor memory\n",
    "\n",
    "### When to use\n",
    "This is applicable when size of the data is large enough to fit into the main memory (RAM).\n",
    "\n",
    "### Steps\n",
    "- Create a Dask Cluster\n",
    "- Create a `dask.distributed.Client` locally and connect to the Dask cluster above.\n",
    "- Read Data using Dask DataFrame. Dask utilizes out of core computing and hence Data is loaded into RAM chunk by chunk. This is how larger than memory is handled.\n",
    "- Format data into the form `tsfresh` expects it to be.\n",
    "- Invoke feature extraction passing the formatted data into `dask_feature_extraction_on_chunk()`\n",
    "- Pivot the output of above state. This is also a Dask DataFrame. The features are extracted and loaded into RAM only when `compute()` is invoked.\n",
    "- Invoke compute(). Output would be a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1, 2. Create a Dask Client and connect it to a Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>16.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:8786' processes=8 threads=8, memory=16.00 GB>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = LocalCluster(n_workers=8, \n",
    "                       threads_per_worker=1, \n",
    "                       scheduler_port=8786, \n",
    "                       memory_limit='2GB')\n",
    "\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Read Data using a Dask DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-474e6c82c249>:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.segment_id = df.segment_id.str.replace(\".csv\", \"\")\n"
     ]
    }
   ],
   "source": [
    "ddf = dd.read_csv(\n",
    "    urlpath=f\"{DATA_DIR}/140*.csv\", \n",
    "    blocksize=None, \n",
    "    dtype=data_types,\n",
    "    include_path_column='segment_id')\n",
    "\n",
    "# Insert a new column with segment_id along with the values from 10 sensors\n",
    "ddf = ddf.map_partitions(get_segment_id_from_path, f\"{DATA_DIR}/\")\n",
    "\n",
    "# Add a column named time with ascending values staring from 0 representing time\n",
    "ddf = ddf.map_partitions(append_time_column)\n",
    "\n",
    "ddf = ddf.loc[0:999, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>sensor_9</th>\n",
       "      <th>sensor_10</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-486.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>-516.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>-785.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>2802.0</td>\n",
       "      <td>1400253000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-567.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-92.0</td>\n",
       "      <td>-591.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>-774.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>2678.0</td>\n",
       "      <td>1400253000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-631.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>-120.0</td>\n",
       "      <td>-620.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-787.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>2517.0</td>\n",
       "      <td>1400253000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-744.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>-215.0</td>\n",
       "      <td>-550.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>-890.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>-240.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>2323.0</td>\n",
       "      <td>1400253000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-725.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-475.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-806.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>1400253000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_1  sensor_2  sensor_3  sensor_4  sensor_5  sensor_6  sensor_7  \\\n",
       "0    -486.0      34.0     -87.0    -516.0     234.0    -785.0     522.0   \n",
       "1    -567.0      95.0     -92.0    -591.0     231.0    -774.0     589.0   \n",
       "2    -631.0     261.0    -120.0    -620.0     212.0    -787.0     433.0   \n",
       "3    -744.0     262.0    -215.0    -550.0     174.0    -890.0     322.0   \n",
       "4    -725.0     318.0    -193.0    -475.0     131.0    -806.0     267.0   \n",
       "\n",
       "   sensor_8  sensor_9  sensor_10  segment_id  time  \n",
       "0     473.0     238.0     2802.0  1400253000     0  \n",
       "1     210.0     252.0     2678.0  1400253000     1  \n",
       "2     120.0     276.0     2517.0  1400253000     2  \n",
       "3    -240.0     334.0     2323.0  1400253000     3  \n",
       "4     -14.0     365.0     2089.0  1400253000     4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Format data into the form `tsfresh` expects it to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf.melt(id_vars=[\"segment_id\", \"time\"],  \n",
    "               value_vars=['sensor_1', 'sensor_4'],  \n",
    "               var_name=\"sensor_type\", \n",
    "               value_name=\"sensor_value\")\n",
    "\n",
    "ddf_grouped = ddf.groupby([\"segment_id\", \"sensor_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Invoke feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh.convenience.bindings import dask_feature_extraction_on_chunk\n",
    "\n",
    "from tsfresh.feature_extraction.settings import MinimalFCParameters\n",
    "\n",
    "features = dask_feature_extraction_on_chunk(ddf_grouped, \n",
    "                                            column_id=\"segment_id\", \n",
    "                                            column_kind=\"sensor_type\", \n",
    "                                            column_value=\"sensor_value\", \n",
    "                                            default_fc_parameters=MinimalFCParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment_id</th>\n",
       "      <th>sensor_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1402674973</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">sensor_1</th>\n",
       "      <th>0</th>\n",
       "      <td>1402674973</td>\n",
       "      <td>sensor_1__sum_values</td>\n",
       "      <td>4700.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1402674973</td>\n",
       "      <td>sensor_1__median</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1402674973</td>\n",
       "      <td>sensor_1__mean</td>\n",
       "      <td>4.70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1402674973</td>\n",
       "      <td>sensor_1__length</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1402674973</td>\n",
       "      <td>sensor_1__standard_deviation</td>\n",
       "      <td>225.85939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          segment_id                      variable       value\n",
       "segment_id sensor_type                                                        \n",
       "1402674973 sensor_1    0  1402674973          sensor_1__sum_values  4700.00000\n",
       "                       1  1402674973              sensor_1__median     0.50000\n",
       "                       2  1402674973                sensor_1__mean     4.70000\n",
       "                       3  1402674973              sensor_1__length  1000.00000\n",
       "                       4  1402674973  sensor_1__standard_deviation   225.85939"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Pivot extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.categorize(columns=[\"variable\"])\n",
    "features = features.reset_index(drop=True)\n",
    "\n",
    "\n",
    "feature_table = features.pivot_table(index=\"segment_id\",\n",
    "                                     columns=\"variable\",\n",
    "                                     values=\"value\",\n",
    "                                     aggfunc=\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Do the actual computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till step 6, the output was a Dask DataFrame. Once we invoke `compute()` the features will actually be computed and the extracted featured will be loaded into the memory. If the size of the extracted features is huge, we may encounter out of memory error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = feature_table.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>sensor_1__sum_values</th>\n",
       "      <th>sensor_1__median</th>\n",
       "      <th>sensor_1__mean</th>\n",
       "      <th>sensor_1__length</th>\n",
       "      <th>sensor_1__standard_deviation</th>\n",
       "      <th>sensor_1__variance</th>\n",
       "      <th>sensor_1__maximum</th>\n",
       "      <th>sensor_1__minimum</th>\n",
       "      <th>sensor_4__sum_values</th>\n",
       "      <th>sensor_4__median</th>\n",
       "      <th>sensor_4__mean</th>\n",
       "      <th>sensor_4__length</th>\n",
       "      <th>sensor_4__standard_deviation</th>\n",
       "      <th>sensor_4__variance</th>\n",
       "      <th>sensor_4__maximum</th>\n",
       "      <th>sensor_4__minimum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140031872</th>\n",
       "      <td>-54490.0</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-54.490002</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>211.928360</td>\n",
       "      <td>4.491363e+04</td>\n",
       "      <td>477.0</td>\n",
       "      <td>-618.0</td>\n",
       "      <td>-27692.0</td>\n",
       "      <td>-60.0</td>\n",
       "      <td>-27.691999</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>368.852356</td>\n",
       "      <td>1.360521e+05</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>-1156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140348256</th>\n",
       "      <td>-12608.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-12.608000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>252.768646</td>\n",
       "      <td>6.389199e+04</td>\n",
       "      <td>639.0</td>\n",
       "      <td>-650.0</td>\n",
       "      <td>2447.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.447000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>209.270218</td>\n",
       "      <td>4.379402e+04</td>\n",
       "      <td>641.0</td>\n",
       "      <td>-567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140851065</th>\n",
       "      <td>-3568.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-3.568000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>553.871704</td>\n",
       "      <td>3.067739e+05</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>-1421.0</td>\n",
       "      <td>15264.0</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>15.264000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>840.077515</td>\n",
       "      <td>7.057302e+05</td>\n",
       "      <td>2239.0</td>\n",
       "      <td>-2409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400253000</th>\n",
       "      <td>-5286.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-5.286000</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>370.556244</td>\n",
       "      <td>1.373119e+05</td>\n",
       "      <td>1117.0</td>\n",
       "      <td>-1364.0</td>\n",
       "      <td>-16044.0</td>\n",
       "      <td>-38.5</td>\n",
       "      <td>-16.044001</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>364.988190</td>\n",
       "      <td>1.332164e+05</td>\n",
       "      <td>1109.0</td>\n",
       "      <td>-929.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400727315</th>\n",
       "      <td>354441.0</td>\n",
       "      <td>976.5</td>\n",
       "      <td>354.441010</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>11997.532227</td>\n",
       "      <td>1.439408e+08</td>\n",
       "      <td>32767.0</td>\n",
       "      <td>-32767.0</td>\n",
       "      <td>-37289.0</td>\n",
       "      <td>406.5</td>\n",
       "      <td>-37.289001</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>12828.428711</td>\n",
       "      <td>1.645686e+08</td>\n",
       "      <td>32767.0</td>\n",
       "      <td>-32767.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "variable    sensor_1__sum_values  sensor_1__median  sensor_1__mean  \\\n",
       "segment_id                                                           \n",
       "140031872               -54490.0             -43.0      -54.490002   \n",
       "140348256               -12608.0               4.5      -12.608000   \n",
       "140851065                -3568.0              11.0       -3.568000   \n",
       "1400253000               -5286.0              19.0       -5.286000   \n",
       "1400727315              354441.0             976.5      354.441010   \n",
       "\n",
       "variable    sensor_1__length  sensor_1__standard_deviation  \\\n",
       "segment_id                                                   \n",
       "140031872             1000.0                    211.928360   \n",
       "140348256             1000.0                    252.768646   \n",
       "140851065             1000.0                    553.871704   \n",
       "1400253000            1000.0                    370.556244   \n",
       "1400727315            1000.0                  11997.532227   \n",
       "\n",
       "variable    sensor_1__variance  sensor_1__maximum  sensor_1__minimum  \\\n",
       "segment_id                                                             \n",
       "140031872         4.491363e+04              477.0             -618.0   \n",
       "140348256         6.389199e+04              639.0             -650.0   \n",
       "140851065         3.067739e+05             1362.0            -1421.0   \n",
       "1400253000        1.373119e+05             1117.0            -1364.0   \n",
       "1400727315        1.439408e+08            32767.0           -32767.0   \n",
       "\n",
       "variable    sensor_4__sum_values  sensor_4__median  sensor_4__mean  \\\n",
       "segment_id                                                           \n",
       "140031872               -27692.0             -60.0      -27.691999   \n",
       "140348256                 2447.0               3.0        2.447000   \n",
       "140851065                15264.0             -11.5       15.264000   \n",
       "1400253000              -16044.0             -38.5      -16.044001   \n",
       "1400727315              -37289.0             406.5      -37.289001   \n",
       "\n",
       "variable    sensor_4__length  sensor_4__standard_deviation  \\\n",
       "segment_id                                                   \n",
       "140031872             1000.0                    368.852356   \n",
       "140348256             1000.0                    209.270218   \n",
       "140851065             1000.0                    840.077515   \n",
       "1400253000            1000.0                    364.988190   \n",
       "1400727315            1000.0                  12828.428711   \n",
       "\n",
       "variable    sensor_4__variance  sensor_4__maximum  sensor_4__minimum  \n",
       "segment_id                                                            \n",
       "140031872         1.360521e+05             1253.0            -1156.0  \n",
       "140348256         4.379402e+04              641.0             -567.0  \n",
       "140851065         7.057302e+05             2239.0            -2409.0  \n",
       "1400253000        1.332164e+05             1109.0             -929.0  \n",
       "1400727315        1.645686e+08            32767.0           -32767.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Close the Dask Cluster & Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
